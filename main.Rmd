---
title: "main"
author: "Jonas Barth, Mattia Castaldo, Matteo Migliarini"
date: "2023-02-03"
output: html_document
---

# Index
- [Simulation Study](#simulation-study)
    - [Setup](#parameter-setup)
    - [Creating Data](#creating-data)
    

# Setup
```{r setup, include=FALSE}
load("hw3_data.RData")
library('dplyr')
library('pROC')
library('transport')
library('boot')
library('InformationValue')
```


# Simulation Study {#simulation-study}
Repeat $M$ times:

1. pick two k-variate distributions to sample from. Each distribution represents one class.
1. sample $n_0$ and $n_1$ number of samples from the respective distributions.
1. train a binary classifier
1. do permutation test (slide 8)
Experiment with different:

distributions
sample sizes
Finally, summarise results.

## Setting up parameters {#parameter-setup}
We set up the following parameters for the **simulation study**. We will sample from an **exponential** and from a **normal** distribution, which require the parameters $\labmda, \mu, \sigma$ to be set. We also define the simulation size $M$, the number of dimensions $k$ for each distribution, and the number of samples from each distribution, $n0$ and $n1$ respectively.
```{r hyperparameters}
M = 1e2
P = 10

k = 5
n0 = 100
n1 = 150

lambda = 0.5
mu = 1 / lambda
sigma = mu
```

## Creating Data {#creating-data}
```{r}
nargs.func <- function(func) length(as.list(args(func))) - 1

random.distro <- function(n, eps = 1e-10, max = 2) {
  #' Generates a univariate random distribution with n samples.
  rd <- sample(1:6, 1)[[1]]
  noise = rnorm(n, 0, max)
  
  if (rd==1) {
    rate = runif(1, eps, max)
    X = rexp(n,rate)
  } else if (rd ==2) {
    mu = runif(1,-max,max)
    sigma = runif(1, eps, max)
    X = rnorm(n, mu, sigma)
  } else if (rd == 3) {
    shape = runif(1, 0, max)
    scale = runif(1, eps, max)
    X = rgamma(n, shape, scale = scale)
  } else if (rd == 4) {
    alpha = runif(1, 0, max)
    beta  = runif(1, 0, max)
    X = rbeta(n, alpha, beta)
  } else if (rd == 5) {
    df  = runif(1, eps, max)
    X = rt(n, df)
  } else if (rd == 6) {
    m = runif(1, -max, 0)
    M = runif(1, 0, max)
    X =  runif(n, m, M)
  }
  
  return(X + noise)
}

random.data <- function(n, k) {
  #' Generates a single k-variate random distribution with n samples.
  cols = list()
  for (i in 1:k)
    cols[[paste(i)]] = random.distro(n)
  
  return(data.frame(cols))
}

random.data(100,5)
```


```{r}
X = random.data(100, 5)
Y = random.data(100, 5)

wasserstein(pp(X), pp(Y))
subwasserstein(pp(X), pp(Y), 30, 100)

#sample(X, 10)
```


```{r}
random_distro <- function(n) {
  i = random
}


create_df = function(n0, n1, k) {
    #' Creates a dataframe with samples from the two distributions.
    #' 
    #' @param n0 number of samples from dist0
    #' @param n1 number of samples from dist1
    #' @param k number of features
    #' 
    #' @return a dataframe with n0 samples from dist0, n1 samples from dist1, and a label column.
    X0 = random.data(n0, k)
    y0 = rep(0, n0)
    
    X1 = random.data(n1, k)
    y1 = rep(1, n1)
    
    y = rep(c(0, 1), c(n0, n1))
    dim(y) = c(n0 + n1, 1)
    
    
    n.min = min(n0, n1)
    X0.sample = X0[sample(nrow(X0), n.min), ]
    X1.sample = X1[sample(nrow(X1), n.min), ]
    d = wasserstein(pp(X0.sample), pp(X1.sample))

    X = rbind(X0, X1)
    df = data.frame(X)
    df$label = y
    df = df[sample(nrow(df), nrow(df)), ]
    
    generated = list()
    generated$df = df
    generated$distance = d
    
    return(generated)
}
```


## Simulation Loop {#simulation-loop}
```{r simulation loop}
find_cutoff <- function(df) {
  model = glm(formula=label ~ ., data=df, family=binomial)
  y_pred = predict(model, df)
  t = as.numeric(auc(df$label, y_pred))
  return(t)
}

alpha = 0.05
tests = integer(M)
dists = numeric(M)
results = vector(length = M)

simulate = function(M, n0, n1, k, create.data) {
    #' Simulates operating characteristics of a testing procedure for two distributions.
    #' @param M the number of simulations
    #' @param n0 the number of samples to draw from the first distribution.
    #' @param n1 the number of samples to draw from the second distribution.
    #' @param k the number of features in each distribution.
    #' @param create.data a function for sampling from the distributions.
    #' @return a result vector with p-values from the testing procedure.
    
    results = vector(length = M)

    for (i in 1:M) {
        generated = create.data(n0, n1, k)
        df = generated$df
        distance = generated$distance

        model = glm(formula=label ~ ., data=df, family=binomial)
        
        y_pred = predict(model, df, type=c("response"))
        df$y_pred = y_pred
        y_pred_class_1 = df[df$label == 1,"y_pred"]
        y_pred_class_0 = df[df$label == 0,"y_pred"]
       
        
        ks.result = ks.test(y_pred_class_0, y_pred_class_1)
        
        results[i] = ks.result$p.value
    }
    return(results)
} 
```

```{r warning=FALSE}
simulate(200, n0, n1, k, create_df)
```







# 1. Load and pool {#load-and-pool-data}
First we normalise data coming from different labs, as the caltech lab and trinity lab have a very different scale. By doing this we hope to mitigate some negative effects on the pooling when later we'll try to use the mean to summarize the values across subjects or time, as a very different scale would have highly impacted the mean values.

```{r Correct lab effect}
asd = bind_rows(asd_sel, .id = 'id')
asd$src = 'asd'
td  = bind_rows(td_sel, .id = 'id')
td$src  = 'td'
td$lab  = ifelse(grepl('trinity', td$id, fixed = TRUE), 'trinity', 'caltech')
asd$lab = ifelse(grepl('trinity', asd$id, fixed = TRUE), 'trinity', 'caltech')

all = rbind(asd, td)

all[all$lab=='caltech',2:117] = scale(all[all$lab=='caltech',2:117])
all[all$lab=='trinity',2:117] = scale(all[all$lab=='trinity',2:117])


asd = all[all$src == 'asd', 2:117]
td  = all[all$src == 'td', 2:117]
```

## Pooling

We tried pooling data together in different manners, by mean or by median, across subjects or across time.

Pool data together by mean across subjects:
```{r mean per subject}
apply_per_subject <- function(df, func, subject_num = 12, jump = 145) {
  df.pool = data.frame()
  for(i in 1:jump) {
    el = apply(df[seq(i, by=jump, length.out=subject_num), ],2, func)
    df.pool = rbind(df.pool, el)
  }
  colnames(df.pool) = colnames(df)
  return(df.pool)
}

asd.pool = apply_per_subject(asd, mean)
td.pool  = apply_per_subject(td, mean)
all.pool = rbind(asd.pool,td.pool)
```

Pool data together by median across subjects:
```{r median per subject}
asd.pool = apply_per_subject(asd, median)
td.pool  = apply_per_subject(td, median)
all.pool = rbind(asd.pool,td.pool)
```

Pool data together by mean across time:
```{r mean per time, eval=FALSE}
apply_per_time <- function(df, func, timestamps = 145, subjects_num = 12) {
  df.pool = data.frame()
  for(i in 0:11) {
    el = apply(df[seq(1+i*timestamps, length.out=timestamps), ],2, func)
    df.pool = rbind(df.pool, el)
  }
  colnames(df.pool) = colnames(df)
  return(df.pool)
}

asd.pool = apply_per_time(asd, mean)
td.pool  = apply_per_time(td, mean)
```

Pool data together by median across time:
```{r median per time, eval=FALSE}
asd.pool = apply_per_time(asd, median)
td.pool  = apply_per_time(td, median)
```

We noticed that the pooling that works the best is the one using **median across subjects**, since it's the only one that gives us a decent amount of correlations.
